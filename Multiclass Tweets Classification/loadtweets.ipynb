{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import string\n",
    "\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer keys and access tokens, used for OAuth\n",
    "consumer_key = 'ZE0w9dhnGHcWMKBqqvhQe2rYc'\n",
    "consumer_secret = '96cnmIEGxDIsErs3HyyPXiayrPw9pedxNuOmwF9a3LMruCJaKl'\n",
    "access_token = '1971207074-7jQ7P9e0dyDhVy0kMN3fva4PWGgtvI7c1xDXe2O'\n",
    "access_token_secret = 'P3yKKm3okxM3ydYuAb57dD2uqcziZW7p9I3owndTFHA4G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_dict = {\n",
    "    'Donald Trump': 'realDonaldTrump',\n",
    "    'Bernie Sanders': 'BernieSanders',\n",
    "    'Barack Obama': 'BarackObama',\n",
    "    'Joe Biden': 'JoeBiden',\n",
    "    'Hillary Clinton': 'HillaryClinton',\n",
    "    'Kamala Harris': 'KamalaHarris',\n",
    "    'Rudy Giuliani': 'RudyGiuliani',\n",
    "    'Ivanka Trump': 'IvankaTrump',\n",
    "    'Bill Gates': 'BillGates',\n",
    "    'Elon Musk': 'elonmusk'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_remove_url(x):\n",
    "    return re.sub(r'(http|www.)\\S+', '', x).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(x):\n",
    "    try:\n",
    "        hashtags = re.findall(r\"#(\\w+)\", x) # Extract hashtags\n",
    "        if not hashtags: return np.nan\n",
    "        elif isinstance(hashtags, list): return ', '.join(hashtags) \n",
    "        else: return hashtags\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mentions(x):\n",
    "    try:\n",
    "        mentions = re.findall(r\"@(\\w+)\", x) # Extract mentions\n",
    "        if not mentions: return np.nan\n",
    "        if isinstance(mentions, list): return ', '.join(mentions)\n",
    "        else: return mentions\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_details(x):\n",
    "    length = len(x) # lenght if each tweet\n",
    "    spaces = sum([1 for l in x if l.isspace()]) # how many spaces in each tweet\n",
    "    uppers = sum([1 for l in x if l.isupper()]) # how many uppercases in each tweet\n",
    "    punctuations  = sum([1 for l in x if l in string.punctuation]) # how many punctuations in each tweet\n",
    "    questionsmark = x.count('?') # how many question marks in each tweet\n",
    "    explainations = x.count('!') # how many explaination marks in each tweet\n",
    "    return length, spaces, uppers, punctuations, questionsmark, explainations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_tweets(x):\n",
    "    try:\n",
    "        x = str(x)\n",
    "        # Spacy pipeline\n",
    "        tweet = nlp(x)\n",
    "        # Extract lemmatized words in lower case format if not digits, not punctuation, not stopword, and lenght not less than 2 \n",
    "        tweet = ' '.join([toke8888/?token=e4605cac42ba1e4bcf36167299d35b578fa279a6be911786n.lemma_.lower() for token in tweet if not token.is_stop and not token.is_punct and not token.text.isdigit() and len(token.text) > 2])\n",
    "        return tweet\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_status(x):\n",
    "    if x == 0: return 'Neutral'\n",
    "    elif x > 0.00: return 'Positive'\n",
    "    elif x < 0.00: return 'Negative'\n",
    "    else: return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_status(x):\n",
    "    if x <= 0.50: return 'Objective'\n",
    "    elif x > 0.50: return 'Subjective'\n",
    "    else: 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polarity and Subjectivity percentages and status\n",
    "def polarity_subjectivity(x):\n",
    "    try:\n",
    "        x = str(x)\n",
    "        analysis = TextBlob(x)\n",
    "        polarity = round(analysis.polarity, 2)\n",
    "        subjectivity   = round(analysis.subjectivity, 2)\n",
    "        polarity_class = polarity_status(polarity)\n",
    "        subjectivity_class = subjectivity_status(subjectivity)\n",
    "        return polarity_class, subjectivity_class\n",
    "    except:\n",
    "        return np.nan, np.nan        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_the_day(x):\n",
    "    try:\n",
    "        if x in [5,6,7,8,9,10,11]: return 'Morning'\n",
    "        elif x in [12,13,14,15,16]: return 'Afternoon' \n",
    "        elif x in [17,18,19]: return 'Evening'\n",
    "        elif x in [20,21,22,23,24,1,2,3,4]: return 'Night'\n",
    "        else: 'Unknown'\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tweets(profile, name, num):\n",
    "    \n",
    "    tweets = api.user_timeline(screen_name = profile, count = num, include_rts = False, tweet_mode = 'extended')\n",
    "    \n",
    "    all_tweets = []\n",
    "    all_tweets.extend(tweets)\n",
    "    oldest_id = tweets[-1].id\n",
    "\n",
    "    while True:\n",
    "        tweets = api.user_timeline(screen_name = profile, count = num, include_rts = False, max_id = oldest_id - 1, tweet_mode = 'extended')\n",
    "        if len(tweets) == 0:\n",
    "            break\n",
    "        oldest_id = tweets[-1].id\n",
    "        all_tweets.extend(tweets)\n",
    "    \n",
    "    profile_name    = []\n",
    "    created_date    = []\n",
    "    created_hour    = []\n",
    "    created_weekday = []\n",
    "    favorite_count  = []\n",
    "    retweet_count   = []\n",
    "    source_device   = []\n",
    "    tweet_text      = []\n",
    "    clean_tweet     = []\n",
    "    \n",
    "    length_list     = []\n",
    "    spaces_list     = []\n",
    "    uppers_list     = []\n",
    "    punctuations_list  = []\n",
    "    questionsmark_list = []\n",
    "    explainations_list = []\n",
    "    \n",
    "    day_part_list    = []\n",
    "    hashtags_list    = []\n",
    "    mentions_list    = []\n",
    "    clean_tweet_list = []\n",
    "    polarity_class_list = []\n",
    "    subjectivity_class_list = []\n",
    "        \n",
    "    for tweet in all_tweets:\n",
    "       \n",
    "        try: profile_name.append(name) \n",
    "        except: profile_name.append(np.nan)\n",
    "            \n",
    "        try: created_date.append(tweet.created_at) \n",
    "        except: created_date.append(np.nan)\n",
    "        \n",
    "        try: created_hour.append(tweet.created_at.hour) \n",
    "        except: created_hour.append(np.nan)\n",
    "        \n",
    "        try: created_weekday.append(tweet.created_at.weekday()) \n",
    "        except: created_weekday.append(np.nan)\n",
    "        \n",
    "        try: favorite_count.append(tweet.favorite_count) \n",
    "        except: favorite_count.append(np.nan)\n",
    "        \n",
    "        try: retweet_count.append(tweet.retweet_count) \n",
    "        except: retweet_count.append(np.nan)\n",
    "        \n",
    "        try: source_device.append(tweet.source.split()[-1]) \n",
    "        except: source_device.append(np.nan)\n",
    "        \n",
    "        try: tweet_text.append(tweet.full_text) \n",
    "        except: tweet_text.append(np.nan)\n",
    "        \n",
    "        day_part    = part_of_the_day(tweet.created_at.hour)\n",
    "        clean_tweet = re_remove_url(tweet.full_text)\n",
    "        length, spaces, uppers, punctuations, questionsmark, explainations = extract_text_details(clean_tweet)\n",
    "        hashtags    = extract_hashtags(clean_tweet)\n",
    "        mentions    = extract_mentions(clean_tweet)\n",
    "        clean_tweet = cleaning_tweets(clean_tweet)\n",
    "        polarity_class, subjectivity_class = polarity_subjectivity(clean_tweet)\n",
    "    \n",
    "        length_list.append(length)\n",
    "        spaces_list.append(spaces)\n",
    "        uppers_list.append(uppers)\n",
    "        punctuations_list.append(punctuations)\n",
    "        questionsmark_list.append(questionsmark)\n",
    "        explainations_list.append(explainations)\n",
    "        \n",
    "        day_part_list.append(day_part)\n",
    "        hashtags_list.append(hashtags)\n",
    "        mentions_list.append(mentions)\n",
    "        clean_tweet_list.append(clean_tweet)\n",
    "        polarity_class_list.append(polarity_class)\n",
    "        subjectivity_class_list.append(subjectivity_class)\n",
    "        \n",
    "    dataframe_dict = {  \n",
    "        'created_date': created_date,\n",
    "        'profile_name': profile_name,\n",
    "        'created_hour': created_hour, \n",
    "        'created_weekday': created_weekday,\n",
    "        'favorite_count': favorite_count,\n",
    "        'retweet_count': retweet_count,\n",
    "        'source_device': source_device,\n",
    "        'tweet_text': tweet_text,\n",
    "        \n",
    "        'length': length_list,\n",
    "        'spaces': spaces_list,\n",
    "        'uppers': uppers_list,\n",
    "        'punctuations': punctuations_list,\n",
    "        'questionsmark': questionsmark_list,\n",
    "        'explainations': explainations_list,\n",
    "        \n",
    "        'day_part': day_part_list,\n",
    "        'hashtags': hashtags_list,\n",
    "        'mentions': mentions_list,\n",
    "        'clean_tweet': clean_tweet_list,\n",
    "        'polarity_class': polarity_class_list,\n",
    "        'subjectivity_class': subjectivity_class_list\n",
    "    }\n",
    "    \n",
    "    print(f'Done with {len(all_tweets)} for {name}')\n",
    "    \n",
    "    return pd.DataFrame(dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1998 for Donald Trump\n",
      "Done with 2596 for Bernie Sanders\n",
      "Done with 2876 for Barack Obama\n",
      "Done with 3008 for Joe Biden\n",
      "Done with 2530 for Hillary Clinton\n",
      "Done with 2682 for Kamala Harris\n",
      "Done with 2346 for Rudy Giuliani\n",
      "Done with 1808 for Ivanka Trump\n",
      "Done with 3027 for Bill Gates\n",
      "Done with 3003 for Elon Musk\n"
     ]
    }
   ],
   "source": [
    "dataframes_list = []\n",
    "\n",
    "for name, profile in account_dict.items():\n",
    "    dataframes_list.append(download_tweets(profile, name, 200))\n",
    "    sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>profile_name</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>created_weekday</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source_device</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>length</th>\n",
       "      <th>spaces</th>\n",
       "      <th>uppers</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>questionsmark</th>\n",
       "      <th>explainations</th>\n",
       "      <th>day_part</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>polarity_class</th>\n",
       "      <th>subjectivity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-20 19:23:18</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>68330</td>\n",
       "      <td>19058</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>https://t.co/8S0ePCOCOG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Evening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-20 17:51:12</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>106968</td>\n",
       "      <td>32162</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Wow! https://t.co/gAttnzPa5d</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Evening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wow</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-20 16:52:28</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>220867</td>\n",
       "      <td>37540</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Cute! https://t.co/bMkuaxd7lL</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cute</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-12-20 16:30:59</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>104008</td>\n",
       "      <td>19277</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>David is a great guy and patriot. Thank you La...</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>david great guy patriot thank lauren</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-12-20 05:26:49</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>384045</td>\n",
       "      <td>80599</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>GREATEST ELECTION FRAUD IN THE HISTORY OF OUR ...</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greatest election fraud history country</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25873</td>\n",
       "      <td>2020-02-09 06:45:25</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5032</td>\n",
       "      <td>167</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>@Erdayastronaut First two domes in frame are f...</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Erdayastronaut</td>\n",
       "      <td>@erdayastronaut dome frame sn2 sn1 thrust dome</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25874</td>\n",
       "      <td>2020-02-09 05:36:01</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>70262</td>\n",
       "      <td>2392</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Back in Boca https://t.co/RjiWpW28PT</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Morning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boca</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25875</td>\n",
       "      <td>2020-02-08 23:11:50</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>25192</td>\n",
       "      <td>747</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>@neiltyson Including hypothesizing that this s...</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neiltyson</td>\n",
       "      <td>@neiltyson include hypothesize statement wrong...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25876</td>\n",
       "      <td>2020-02-08 23:10:37</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>3064</td>\n",
       "      <td>68</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>@flcnhvy True</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flcnhvy</td>\n",
       "      <td>@flcnhvy true</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25877</td>\n",
       "      <td>2020-02-08 13:16:49</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>58042</td>\n",
       "      <td>7625</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>@SachaBaronCohen #DeleteFacebook It’s lame</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>DeleteFacebook</td>\n",
       "      <td>SachaBaronCohen</td>\n",
       "      <td>@sachabaroncohen deletefacebook lame</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Subjective</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25878 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              created_date  profile_name  created_hour  created_weekday  \\\n",
       "0      2020-12-20 19:23:18  Donald Trump            19                6   \n",
       "1      2020-12-20 17:51:12  Donald Trump            17                6   \n",
       "2      2020-12-20 16:52:28  Donald Trump            16                6   \n",
       "3      2020-12-20 16:30:59  Donald Trump            16                6   \n",
       "4      2020-12-20 05:26:49  Donald Trump             5                6   \n",
       "...                    ...           ...           ...              ...   \n",
       "25873  2020-02-09 06:45:25     Elon Musk             6                6   \n",
       "25874  2020-02-09 05:36:01     Elon Musk             5                6   \n",
       "25875  2020-02-08 23:11:50     Elon Musk            23                5   \n",
       "25876  2020-02-08 23:10:37     Elon Musk            23                5   \n",
       "25877  2020-02-08 13:16:49     Elon Musk            13                5   \n",
       "\n",
       "       favorite_count  retweet_count source_device  \\\n",
       "0               68330          19058        iPhone   \n",
       "1              106968          32162        iPhone   \n",
       "2              220867          37540        iPhone   \n",
       "3              104008          19277        iPhone   \n",
       "4              384045          80599        iPhone   \n",
       "...               ...            ...           ...   \n",
       "25873            5032            167        iPhone   \n",
       "25874           70262           2392        iPhone   \n",
       "25875           25192            747        iPhone   \n",
       "25876            3064             68        iPhone   \n",
       "25877           58042           7625        iPhone   \n",
       "\n",
       "                                              tweet_text  length  spaces  \\\n",
       "0                                https://t.co/8S0ePCOCOG       0       0   \n",
       "1                           Wow! https://t.co/gAttnzPa5d       5       1   \n",
       "2                          Cute! https://t.co/bMkuaxd7lL       6       1   \n",
       "3      David is a great guy and patriot. Thank you La...      52      10   \n",
       "4      GREATEST ELECTION FRAUD IN THE HISTORY OF OUR ...      56       8   \n",
       "...                                                  ...     ...     ...   \n",
       "25873  @Erdayastronaut First two domes in frame are f...      78      13   \n",
       "25874               Back in Boca https://t.co/RjiWpW28PT      13       3   \n",
       "25875  @neiltyson Including hypothesizing that this s...      68       8   \n",
       "25876                                      @flcnhvy True      13       1   \n",
       "25877         @SachaBaronCohen #DeleteFacebook It’s lame      42       3   \n",
       "\n",
       "       uppers  punctuations  questionsmark  explainations   day_part  \\\n",
       "0           0             0              0              0    Evening   \n",
       "1           1             1              0              1    Evening   \n",
       "2           1             1              0              1  Afternoon   \n",
       "3           3             2              0              1  Afternoon   \n",
       "4          45             3              0              3    Morning   \n",
       "...       ...           ...            ...            ...        ...   \n",
       "25873       6             2              0              0    Morning   \n",
       "25874       2             0              0              0    Morning   \n",
       "25875       1             1              0              0      Night   \n",
       "25876       1             1              0              0      Night   \n",
       "25877       6             2              0              0  Afternoon   \n",
       "\n",
       "             hashtags         mentions  \\\n",
       "0                 NaN              NaN   \n",
       "1                 NaN              NaN   \n",
       "2                 NaN              NaN   \n",
       "3                 NaN              NaN   \n",
       "4                 NaN              NaN   \n",
       "...               ...              ...   \n",
       "25873             NaN   Erdayastronaut   \n",
       "25874             NaN              NaN   \n",
       "25875             NaN        neiltyson   \n",
       "25876             NaN          flcnhvy   \n",
       "25877  DeleteFacebook  SachaBaronCohen   \n",
       "\n",
       "                                             clean_tweet polarity_class  \\\n",
       "0                                                    NaN        Neutral   \n",
       "1                                                    wow       Positive   \n",
       "2                                                   cute       Positive   \n",
       "3                   david great guy patriot thank lauren       Positive   \n",
       "4                greatest election fraud history country       Positive   \n",
       "...                                                  ...            ...   \n",
       "25873     @erdayastronaut dome frame sn2 sn1 thrust dome        Neutral   \n",
       "25874                                               boca        Neutral   \n",
       "25875  @neiltyson include hypothesize statement wrong...       Negative   \n",
       "25876                                      @flcnhvy true       Positive   \n",
       "25877               @sachabaroncohen deletefacebook lame       Negative   \n",
       "\n",
       "      subjectivity_class  \n",
       "0              Objective  \n",
       "1             Subjective  \n",
       "2             Subjective  \n",
       "3             Subjective  \n",
       "4             Subjective  \n",
       "...                  ...  \n",
       "25873          Objective  \n",
       "25874          Objective  \n",
       "25875         Subjective  \n",
       "25876         Subjective  \n",
       "25877         Subjective  \n",
       "\n",
       "[25878 rows x 20 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dataframes_list).reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('multiclass_text_classification.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
